---
batchScheduler:
  name: 'default-scheduler'
  queue: 'root.default'
configMaps: {}
# Driver parameters
driver:
  # Number of cores allocated to driver
  cores: 0  # coreRequest is the preferred way if you use this you MUST set coreRequest to empty string
  # Number of cores allocated to executor (but expressed as a request allowing more granularity)
  coreRequest: 1000m  # If you use this you MUST set cores to 0
  # Hard limit on CPU cores for the pod
  coreLimit: "1200m"
  # Memory limit for pod
  memory: "4096m"
  # MemoryOverhead is the amount of off-heap memory to allocate in cluster mode, in MiB unless otherwise specified.
  memoryOverhead: "2700m"
  # Termination grace period seconds for the pod
  terminationGracePeriodSeconds: 30
  # Extra environment variable to be added to drivers as per envvar-v1-core spec
  # https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#envvar-v1-core
  extraEnv: []
  # A priority class that can be used for the driver of the deployed spark application.
  # priorityClassName: <value>
# Executor parameters
executor:
  # Number of cores allocated to executor
  cores: 0  # coreRequest is the preferred way if you use this you MUST set coreRequest to empty string
  # Number of cores allocated to executor (but expressed as a request allowing more granularity)
  coreRequest: 1000m  # If you use this you MUST set cores to 0
  # Hard limit on CPU cores for the pod
  coreLimit: "1200m"
  # Number of executors to spawn by default
  instances: 1
  # Memory limit for pod
  memory: "4096m"
  # MemoryOverhead is the amount of off-heap memory to allocate in cluster mode, in MiB unless otherwise specified.
  memoryOverhead: "2700m"
  # Termination grace period seconds for the pod
  terminationGracePeriodSeconds: 30
  # Extra environment variable to be added to executors as per envvar-v1-core spec
  # https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#envvar-v1-core
  extraEnv: []
existingConfigMaps: true
global:
  # Extra environment variable to be added to drivers and executors as per envvar-v1-core spec
  # https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#envvar-v1-core
  extraEnv: []
imagePullPolicy: "IfNotPresent"
ingress:
  enabled: false
ingressRoute:
  enabled: false
# Port of the HTTP server run by the Prometheus JMX exporter
jmxPort: 8090
pythonVersion: 3
pythonMinorVersion: 8
service:
  enabled: false
  type: "ClusterIP"
sparkVersion: "2.4.5"
rbac:
  # Wether to create RBAC resources
  create: false
  createClusterRole: true
  clusterRoleName: ""  # empty default results in {service-account-name}-cluster-role
  clusterRoleBindingName: ""  # empty default results in {service-account-name}-cluster-role-{namespace}
  createClusterRoleBinding: true
  serviceAccountDriver: default
  serviceAccountExecutor: default
  # Where the spark-operator lives
  sparkOperator:
    namespace: spark-operator
    serviceAccount: spark-operator
  clusterRole:
    rules:
      - apiGroups:
          - 'policy'
        resources:
          - 'podsecuritypolicies'
        verbs:
          - 'use'
  clusterRoleBinding:
    subjects: {}
restartPolicy:
  type: "OnFailure"
  onFailureRetries: 3
  onFailureRetryInterval: 10
  onSubmissionFailureRetries: 5
  onSubmissionFailureRetryInterval: 20
spark_ui:
  port: 4040
  ingress:
    enabled: false
# Run in privileged mode
privileged: false
# TimeToLiveSeconds defines the Time-To-Live (TTL) duration in seconds for this SparkApplication after its termination
timeToLiveSeconds: 172800
# Scrape pod metrics with Prometheus
monitoring:
  podMonitor:
    enabled: false
