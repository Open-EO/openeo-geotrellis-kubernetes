---
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: job-direct-batch-test
  namespace: spark-jobs
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: vito-docker.artifactory.vgt.vito.be/openeo-geotrellis-kube:20220325-46
  imagePullPolicy: Always
  timeToLiveSeconds: 604800
  mainApplicationFile: local:///opt/openeo/lib64/python3.8/site-packages/openeogeotrellis/deploy/batch_job.py
  arguments:
    - "/batch_jobs/2847ac3d-b642-480c-8709-478bc3ec90fc/job_specification.json"
    - "/batch_jobs/2847ac3d-b642-480c-8709-478bc3ec90fc"
    - "out_file"
    - "log"
    - "job_metadata.json"
    - "1.0.0"
    - "[]"
    - "spark"
    - "false"
  dynamicAllocation:
    enabled: true
    initialExecutors: 2
    minExecutors: 2
    maxExecutors: 10
  sparkConf:
    "spark.rpc.message.maxSize": "200"
    "spark.rdd.compress": "true"
    "spark.driver.maxResultSize": "5g"
    "spark.excludeOnFailure.enabled": "false"
    "spark.excludeOnFailure.killExcludedExecutors": "true"
    "spark.speculation": "true"
    "spark.speculation.interval": "5000ms"
    "spark.speculation.multiplier": "4"
    "spark.kryoserializer.buffer.max": "1g"
    "spark.kryo.classesToRegister": "org.openeo.geotrellis.layers.BandCompositeRasterSource,geotrellis.raster.RasterRegion,geotrellis.raster.geotiff.GeoTiffResampleRasterSource,geotrellis.raster.RasterSource,geotrellis.raster.SourceName,geotrellis.raster.geotiff.GeoTiffPath"
    "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    "spark.dynamicAllocation.enabled": "true"
    "spark.dynamicAllocation.shuffleTracking.enabled": "true"
    "spark.decommission.enabled": "true"
    "spark.storage.decommission.enabled": "true"
    "spark.storage.decommission.rddBlocks.enabled": "true"
    "spark.storage.decommission.shuffleBlocks.enabled": "true"
    "spark.eventLog.dir": "s3a://spark-history/history_prod"
    "spark.hadoop.fs.s3a.endpoint": "https://s3.waw2-1.cloudferro.com"
    "spark.hadoop.fs.s3a.path.style.access": "true"
    "spark.hadoop.fs.s3a.aws.credentials.provider": "com.amazonaws.auth.EnvironmentVariableCredentialsProvider"
    "spark.eventLog.enabled": "true"
    "spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.options.claimName": "OnDemand"
    "spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.options.storageClass": "default"
    "spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.options.sizeLimit": "20Gi"
    "spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.mount.path": "/spark_tmp"
    "spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.mount.readOnly": "false"
    "spark.kubernetes.allocation.batch.size": "1"
    "spark.kubernetes.allocation.batch.delay": "30s"
    "spark.kubernetes.driver.ownPersistentVolumeClaim": "true"
    "spark.kubernetes.driver.reusePersistentVolumeClaim": "true"
    "spark.kubernetes.allocation.maxPendingPods": "5"
  sparkVersion: "3.2.0"
  restartPolicy:
    type: OnFailure
    onFailureRetries: 0
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 5
    onSubmissionFailureRetryInterval: 20
  volumes:
    - name: "eodata"
      hostPath:
        path: "/eodata"
        type: DirectoryOrCreate
    - name: "shared-pod-volume"
      hostPath:
        path: "/shared_pod_volume"
        type: "DirectoryOrCreate"
    - name: "spark-local-dir-1"
      hostPath:
        path: "/opt/spark_tmp"
        type: "DirectoryOrCreate"
  driver:
    envVars:
      SPARK_USER: "spark"
      OPENEO_CATALOG_FILES: "/opt/layercatalog.json"
      KUBE: "true"
      AWS_ACCESS_KEY_ID: NO_KEY_SET
      AWS_SECRET_ACCESS_KEY: NO_KEY_SET
      AWS_VIRTUAL_HOSTING: "FALSE"
      SWIFT_URL: "https://s3.waw2-1.cloudferro.com"
      SWIFT_BUCKET: "OpenEO-data"
      ZOOKEEPERNODES: "zookeeper.zookeeper.svc.cluster.local:2181"
      OPENEO_S1BACKSCATTER_ELEV_GEOID: "/opt/openeo-vito-aux-data/egm96.grd"
      OTB_HOME: "/usr"
      OTB_APPLICATION_PATH: "/usr/lib/otb/applications"
      GDAL_NUM_THREADS: "2"
      GDAL_CACHEMAX: "200"
      GDAL_DISABLE_READDIR_ON_OPEN: "EMPTY_DIR"
      GDAL_HTTP_MERGE_CONSECUTIVE_RANGES: "YES"
      PYTHONPATH: "$PYTHONPATH:/opt/openeo/lib/python3.8/site-packages/"
      VSI_CACHE: "TRUE"
    cores: 2
    javaOptions: "-Dscala.concurrent.context.maxThreads=2 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/projects/OpenEO/test_mem_dump.hprof -Dlog4j.configuration=/opt/log4j.properties -Dlog4j.debug=true -Dpixels.treshold=1000000 -Dsoftware.amazon.awssdk.http.service.impl=software.amazon.awssdk.http.urlconnection.UrlConnectionSdkHttpService"
    memory: "4G"
    labels:
      version: 3.2.0
      name: test-job-driver
    serviceAccount: openeo
    volumeMounts:
      - name: "eodata"
        mountPath: "/eodata"
      - name: "shared-pod-volume"
        mountPath: "/shared_pod_volume"
      - name: "spark-local-dir-1"
        mountPath: "/spark_tmp"
  executor:
    deleteOnTermination: false
    terminationGracePeriodSeconds: 300
    podSecurityContext:
      fsGroup: 18585
    envVars:
      SPARK_USER: "spark"
      OPENEO_CATALOG_FILES: "/opt/layercatalog.json"
      KUBE: "true"
      AWS_ACCESS_KEY_ID: NO_KEY_SET
      AWS_SECRET_ACCESS_KEY: NO_KEY_SET
      AWS_VIRTUAL_HOSTING: "FALSE"
      SWIFT_URL: "https://s3.waw2-1.cloudferro.com"
      SWIFT_BUCKET: "OpenEO-data"
      ZOOKEEPERNODES: "zookeeper.zookeeper.svc.cluster.local:2181"
      OPENEO_S1BACKSCATTER_ELEV_GEOID: "/opt/openeo-vito-aux-data/egm96.grd"
      OTB_HOME: "/usr"
      OTB_APPLICATION_PATH: "/usr/lib/otb/applications"
      GDAL_NUM_THREADS: "2"
      GDAL_CACHEMAX: "200"
      GDAL_DISABLE_READDIR_ON_OPEN: "EMPTY_DIR"
      GDAL_HTTP_MERGE_CONSECUTIVE_RANGES: "YES"
      PYTHON_MAX_MEMORY: "3657433088"
      PYTHONPATH: "$PYTHONPATH:/opt/openeo/lib64/python3.8/site-packages/"
      VSI_CACHE: "TRUE"
      CPL_DEBUG: "ON"
    cores: 4
    coreRequest: 400m
    memory: "1500m"
    memoryOverhead: "4000m"
    javaOptions: "-Dlog4j.configuration=/opt/log4j.properties -Dscala.concurrent.context.numThreads=15 -Dscala.concurrent.context.maxThreads=15 -Dsoftware.amazon.awssdk.http.service.impl=software.amazon.awssdk.http.urlconnection.UrlConnectionSdkHttpService"
    labels:
      version: 3.2.0
    volumeMounts:
      - name: "eodata"
        mountPath: "/eodata"
      - name: "shared-pod-volume"
        mountPath: "/shared_pod_volume"
  deps:
    jars:
      - 'local:///opt/geotrellis-extensions-2.3.0_2.12-SNAPSHOT.jar'
      - 'local:///opt/geotrellis-backend-assembly-0.4.6-openeo_2.12.jar'
    files:
      - 'local:///opt/layercatalog.json'
  monitoring:
    exposeDriverMetrics: true
    exposeExecutorMetrics: true
    prometheus:
      jmxExporterJar: "/opt/jmx_prometheus_javaagent-0.13.0.jar"
      port: 8090
